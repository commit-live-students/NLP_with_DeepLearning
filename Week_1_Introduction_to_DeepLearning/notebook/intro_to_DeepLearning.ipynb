{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "Start your first steps into the world of Deep Learning  - learn what it means, what it can do(and what it can't), and why it's currently the state of the art model for solving various modern day problems.\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "The concept will introduce you to what AI is and what is need of deep learning in solving certain problems. You will also get a intuitive idea about how deep learning models work. In this concept you will learn:\n",
    "\n",
    "- What is Artifical Intelligence?\n",
    "\n",
    "- What is Deep Learning and its motivation?\n",
    "\n",
    "- Applications of Deep Learning\n",
    "\n",
    "- What is Gradient Descent?\n",
    "\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this concept, you will be able to do the following:\n",
    "\n",
    "- Understand how Artificial Intelligence, Mahcine Learning and Deep Learning are connected.\n",
    "\n",
    "- Know the different applications of Deep learning.\n",
    "\n",
    "- Learn the intuition of how deep learning works.\n",
    "\n",
    "\n",
    "## Pre-requisites\n",
    "Before you start learning this concept, be sure you have already covered\n",
    "\n",
    "- Hands on Linear Algebra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 What is Artifical intelligence?\n",
    "\n",
    "\n",
    "- `\"The age of AI has begun\" - Google engineer `\n",
    "\n",
    "- `\"We have only scratched the surface of possibilities of AI \" -A PHD student`\n",
    "\n",
    "- `\"We plan to use AI systems to analyse data and make better market decisions\" - 'Fortune 500 company' CEO`\n",
    "\n",
    "- `\"AI is here\" - LinkedIn influencer `\n",
    "\n",
    "\n",
    "Artificial intelligence(or AI) is a term that has been part of our technological discussions for decades now. It's a very exciting `buzzword` to talk about and therefore one has to be careful in having a discourse about it without knowing what it exactly is.  \n",
    "\n",
    "\n",
    "AI(among many other definitions) is the science and engineering of making intelligent machines. Engineering the machines to make decisions that normally require human intelligence, such as visual perception, speech recognition, decision-making.  \n",
    "\n",
    "Not surprisingly, there are a lot of ways to simulate human intelligence.\n",
    "\n",
    "\n",
    "Lot of AI of the past(and quite a few of them now) are a pile of rule based systems sometimes involving statistical model mapping raw sensory data to symbolic categories. \n",
    "\n",
    "For e.g. Clap based light bulbs.\n",
    "\n",
    "![](../images/clap.gif)\n",
    "*Source:* <a href=\"https://gifer.com/en/XN87\">GIPHER</a></p>\n",
    "\n",
    "\n",
    "In a manner of simple explanation, it just involves simple rules explicitly programmed by a human hand. \n",
    "The circuit is programmed to detect sounds. `If` clap frequency detected, turn on/off the light. `Else` don't do anything\n",
    "\n",
    "\n",
    "**Machine Learning(ML)**\n",
    "\n",
    "ML is a subset of AI i.e. all ML models are AI models but all AI models are not ML models.\n",
    "\n",
    "Very intuitively put machine learning is defined as learning that involves parsing throug data, learning from that data, and then apply what they’ve learned to make informed decisions. \n",
    "\n",
    "For eg: Amazon Recommender System. \n",
    "\n",
    "Based on your previous shopping data, it tries to recommend items that are usually bought with the items you purchased.\n",
    "\n",
    "Machine learning therefore is dynamic and requires comparatively less human intervention to make certain changes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation for DL\n",
    "\n",
    "Traditional machine learning models are both powerful and efficient in what they do- handle structured data.\n",
    "The fact that one of its uses is driving major business decisions speaks for itself. Churn prediction,  Credit scoring and Consumer targeting are few of the examples where traditional ML models have been dominating.\n",
    "\n",
    "Basic machine learning models do become progressively better at whatever their function is, but they still need some guidance particularly in terms of defining the features. The success of these models highly depends on the feature engineering phase. The better the data scientist is aware of the business domain and requirements, the better features he can conceive which results in better models.\n",
    "\n",
    "What about when dealing with unstructured data(images, text, audio)?\n",
    "\n",
    "### Fake currency identification\n",
    "\n",
    "Consider one of the popular use cases of identifying fake currency notes from original ones.\n",
    "\n",
    "![](../images/currency.PNG)\n",
    "\n",
    "Image Processing domain experts have extracted the features listed in the figure. This manual feature\n",
    "extraction takes huge time and requires heavy domain expertise. For future problems, it’s not feasible to hand-engineer features. Hence, these features have to be automatically extracted preserving the local spatial patterns. \n",
    "\n",
    "\n",
    "Consider another problem of facial recognition system.\n",
    "\n",
    "\n",
    "The input data for us are different images of faces like the following\n",
    "\n",
    "![](../images/l_0.jpg)\n",
    "\n",
    "\n",
    "- The first step is to identify the different pixels of light and dark\n",
    "\n",
    "![](../images/l_1.png)\n",
    "\n",
    "- The second step involves identifying simple edges and shapes\n",
    "\n",
    "![](../images/l_2.png)\n",
    "\n",
    "- Followed by a third step to identify more complex shapes and objects\n",
    "\n",
    "![](../images/l_3.png)\n",
    "\n",
    "- Finally leading to the phase to learn which shapes and objects can be used to define a human face\n",
    "\n",
    "![](../images/l_4.png)\n",
    "\n",
    "This task of creating features would still be possible(though very difficult) if features were consistent. That unfortunately is not the case.\n",
    "\n",
    "For eg: Even for a simple face detection, there can be cases where the face is not centre alligned or we have a side view of the head or we have zoomed/rotated images of face. It becomes a humongous task then to identify similar features that are spread across as different features(A nose facing front will look different from Nose in facing sideways) \n",
    "\n",
    "How will you go about `creating features manually` for a large amount of images in a use case like this?\n",
    "\n",
    "\n",
    "**Manual feature engineering is not scalable.**\n",
    "\n",
    "***\n",
    "#### Self-Driving cars\n",
    "\n",
    "Consider another recent use case involving self- driving cars:\n",
    "\n",
    "![](../images/self_car.gif)\n",
    "\n",
    "When driving a car, we humans subconsciously make a lot of decisions based on the environment around.\n",
    "When to slow down, when to turn, when to steer away if we encounter an obstacle. This is a difficult thing to implement because of two major reasons: \n",
    "\n",
    "1. Lot of features to consider in the environment.(Traffic signals, humans crossing, Roadblocks)\n",
    "\n",
    "2. All decisions are time sensitive. While avoiding collision, say with a person crossing the road, one has to make split second decisions on what to do.\n",
    " \n",
    "It's obvious that for our every object the car sees, it needs to quickly identify the features. classify it and take appropriate actions.\n",
    "\n",
    "How will you go about `creating features manually` for a time-sensitive use case like this?\n",
    "\n",
    "**Manual feature engineering is time-consuming.**\n",
    "\n",
    "***\n",
    "\n",
    "#### Election Prediction!\n",
    "\n",
    "One use case involved taking fifty million Google Street View images and just simply exploring what the Deep Learning network can do with them.It was successful in detecting over twenty two million cars including their make, model and year(which was an expected use case). \n",
    "\n",
    "\n",
    "An unexpected use case was that it was able to successfully find some interesting election insights based on that.\n",
    "\n",
    "For eg: It found out that \"if the number of sedans(a vehicle) encountered during a 15-minute drive through a city is higher than the number of pickup trucks, the city is likely to vote for a Democrat during the next Presidential election (88% chance); otherwise, it is likely to vote Republican (82%).\"\n",
    "\n",
    "We couldn't have put(or thought of) `no. of sedans` or `no. of pickup trucks` to be taken as a feature for predicting people's preference over one party in elections. \n",
    "\n",
    "\n",
    "How will you go about `creating features manually` where the features to take are not clear?\n",
    "\n",
    "**Manual feature engineering is brittle.**\n",
    "\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "When it comes to unstructured data, hand engineered features are time consuming, brittle and not scalable in practice\n",
    "\n",
    "That's where deep learning helps us.\n",
    "\n",
    "![](../images/dl_vs_ml.png)\n",
    "\n",
    "Given a large dataset involving input and output, a deep learning algorithm will try to minimize the difference between its expected and predicted output. By doing this, it tries to identify the association between given inputs and outputs. This results in a deep learning model to generalize to inputs that it hasn’t seen before.\n",
    "\n",
    "The above capability of deep learning replaces manual feature engineering and allows a machine to both learn the features and predict the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications of Deep Learning\n",
    "\n",
    "Before going ahead and understand how deep learning works. Let's look at some of the applications of deep learning that are creating a lot of excitement around the artificial intelligence community at the moment. \n",
    "\n",
    "It has it's use in recognition and generation of images, text, audio and video\n",
    "\n",
    "Let's look at some recent and amazing applications of deep learning that will inspire to get started in deep learning.\n",
    "\n",
    "#### Dynamically personalized thumbnails(Netflix)\n",
    "\n",
    "Due to the introduction of more advanced machine learning algorithms, Netflix is able to achieve  personalization in rankings and layout\n",
    "\n",
    "That helps Netflix not only recommend better movies, but predict better thumbnail images for each individual\n",
    "\n",
    "Consider the movie 'Pulp Fiction' starring Uma Thurman and John Travolta\n",
    "\n",
    "A member who watches many movies featuring Uma Thurman would likely respond positively to the artwork for Pulp Fiction that contains Uma. Meanwhile, a fan of John Travolta may be more interested in watching Pulp Fiction if the artwork features John.\n",
    "\n",
    "![](../images/netflix.png)\n",
    "\n",
    "*Thumbnail generation. [Source](https://medium.com/netflix-techblog/artwork-personalization-c589f074ad76)*\n",
    "\n",
    "\n",
    "#### Automatic Language Translation(KantanMT)\n",
    "\n",
    "This is one of the popular NLP use cases given the rise of globalization.\n",
    "\n",
    "In this task, given words, phrase or sentence in one language, the machine automatically translates it into another language.\n",
    "\n",
    "![](../images/mt.png)\n",
    "\n",
    "*Parallel Corpus: [Source](\n",
    "https://medium.freecodecamp.org/a-history-of-machine-translation-from-the-cold-war-to-deep-learning-f1d335ce8b5)*\n",
    "\n",
    "This has recently been in the rise with lot of companies focusing on portable real time translators\n",
    "\n",
    "\n",
    "\n",
    "A recent use case is `World’s 1st Irish Language Neural Machine Translation Engine` launched by [KantanMT](https://slator.com/press-releases/worlds-1st-irish-language-neural-machine-translation-engine-launched-by-kantanmt-com/)\n",
    "The advanced NMT engines are made with keeping in mind, it's use for translating Irish government legislative texts. \n",
    "\n",
    "\n",
    "#### Caption Generation(Google Photos)\n",
    "\n",
    "In recent times, we have taken it for granted the automatic classification of photos by our computer. \n",
    "\n",
    "For e.g., Google Photos can automatically label your photos for an easier search. \n",
    "\n",
    "A Deep Learning network automatically segments an image and writes short sentences describing each segment with proper English grammar.\n",
    "\n",
    "![](../images/cg.png)\n",
    "\n",
    "*Caption Generation. [Source](https://cs.stanford.edu/people/karpathy/deepimagesent/)*\n",
    "\n",
    "This means that the machine not only learned to classify the elements in the photo, but to actually describe them with English grammar. \n",
    "\n",
    "#### Document Summarization(Microsoft)\n",
    "\n",
    "This is one of the popular use cases.\n",
    "\n",
    "Though text summarisation has been an active research field for almost 20 years, its with the advent of deep learning that has accelerated. Document summarization has various applications including summary of work report, news summary and novel summary.\n",
    "\n",
    "![](../images/ds.png)\n",
    "\n",
    "*Text Summarization: [Source](https://sflscientific.com/data-science-blog/2016/11/17/text-summarization-in-natural-language-processing)* \n",
    "\n",
    "\n",
    "[Microsoft](https://venturebeat.com/2018/11/06/microsoft-researchers-develop-ai-system-that-can-generate-articles-summaries/) recently published paper on (“Structured Neural Summarization“) describing framework that can better identify relationships in  text, enabling it to outperform the current text summarizers available.\n",
    "\n",
    "\n",
    "#### Complex Game Understanding(DeepMind)\n",
    "\n",
    "Google's DeepMind used a Deep Learning technique called Deep Reinforcement Learning to teach a computer to play the Atari game Breakout. \n",
    "\n",
    "The computer wasn't programmed in any way specific to play the game nor were the rules of the game coded. Instead, the machine was given the control of keyboard and its goal was to maximize the score. \n",
    "\n",
    "After initial random movements for an hour (about 200 games), it was able to perform measurably better with a 30-40 percent success rate. \n",
    "With only one more hour of practice, the software never missed the ball and was playing better than any human could. \n",
    "After even more training, the software sort of outsmarted the game, playing more offensively than defensively by strategically hitting the ball in ways that will help it win more efficiently and with less risk of missing.\n",
    "\n",
    "![](../images/ab.png)\n",
    "\n",
    "*DeepMind. [Source](https://www.youtube.com/watch?v=V1eYniJ0Rnk)*\n",
    "\n",
    "\n",
    "Other than arcade games, recently DeepMind's AlphaGo was successfully able to beat human players in the Chinese game of 'Go'(A board game with more configurations than there are atoms in the observable universe)\n",
    "\n",
    "![](../images/alphago.jpg)\n",
    "\n",
    "*AlphaGo. [Source](https://www.bbc.com/news/technology-35785875)*\n",
    "\n",
    "#### Earthquake Prediction(Harvard)\n",
    "\n",
    "Harvard scientists used Deep Learning to teach the machine to the computations used in predictions of earthquakes(viscoelastic computations). \n",
    "Until their paper, these computations were computer intensive, but this application of Deep Learning improved calculation time by `50,000%`. \n",
    "\n",
    "![](../images/earthquake.jpg)\n",
    "\n",
    "*Earthquake model [Video Source](https://arxiv.org/vc/arxiv/papers/1701/1701.08884v1.pdf)\n",
    "[Paper Source](https://www.youtube.com/watch?v=wUEf_LR0NYg)*\n",
    "\n",
    "When it comes to earthquake calculation, timing is important and this improvement can be vital in saving life.\n",
    "\n",
    "\n",
    "It's other use cases include:\n",
    "\n",
    "- Restoration of colour in B/W images\n",
    "\n",
    "\n",
    "- Healthcare diagnosis including body image analysis\n",
    "\n",
    "\n",
    "- Real-Time Behaviour Analysis of objects\n",
    "\n",
    "\n",
    "- Automated machines including Self-Driving cars\n",
    "\n",
    "\n",
    "- Music Composition\n",
    "\n",
    "\n",
    "- Automatic handwriting/ text generation\n",
    "\n",
    "\n",
    "- Energy Market price forecasting\n",
    "\n",
    "\n",
    "- Stock Market Predictions..... and so many more\n",
    "\n",
    "\n",
    "Now we know what Deep Learning is capable of, it's time to answer the important question: **WHAT IS DEEP LEARNING?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 What is DL?\n",
    "\n",
    "To understand Deep Learning a little better, let's try to first understand it's relationship with Machine learning.\n",
    "\n",
    "![](../images/dl_in_ml.png)\n",
    "\n",
    "**Artificial intelligence** is the broad domain involving any technique that enables computers to mimic human behaviour and think intelligently.\n",
    "\n",
    "**Machine learning** is but a subset of artificial intelligence where without being explicitly programmed, machines are able to learn(and glean insights from) the data.\n",
    "\n",
    "**Deep learning** forms an even smaller subset of Machine Learning where it is also able to learn the underlying features using something called `Neural Networks`.\n",
    "\n",
    "### Neural Networks\n",
    "\n",
    "Neural network is the building block of deep learning\n",
    "\n",
    "![](../images/nn.png)\n",
    "\n",
    "Without going much into depth, input layers take in the data, output layers give out predictions and hidden layers are responsible for majority of the computation. The hidden layers have tunable weight and bias parameters that help in the actual “learning” process of a deep learning algorithm.  \n",
    "\n",
    "The “deep” part in deep learning refers to creating deep neural networks. Deep here refers to a neural network with a large amount of layers. With the adding of more weights and biases, the neural network improves its ability to approximate more complex functions.\n",
    "\n",
    "\n",
    "It's no coincidence that the structure of neural networks is inspired by the structure of our brain nerves\n",
    "\n",
    "![](../images/neuron.png)\n",
    "\n",
    "![](../images/neuron_2.jpg)\n",
    "\n",
    "### Why deep learning now?\n",
    "\n",
    "The concept and building blocks of Neural networks date back decades.\n",
    "Let's understand what happened in the recent times that has led to this boom of deep learning.\n",
    "\n",
    "\n",
    "#### Big data\n",
    "\n",
    "![](../images/databoom_1.png)\n",
    "\n",
    "*Boom of data. Source:[SDINTL](https://www.sdintl.com/2018/04/30/big-data-friend-or-foe/)*\n",
    "\n",
    "\n",
    "\n",
    "We have entered the 'big data' age. Owing to these we have large amounts of data and accessing that data has become easier than ever\n",
    "\n",
    "\n",
    "One interesting thing to note is as the amount of data increases, the performance of traditional learning algorithms(for eg. SVM, Logistic regression) stops improving by much. \n",
    "\n",
    "In the case of neural networks though, the performance of the model increases with an increase in the data.\n",
    "\n",
    "\n",
    "![](../images/big_data.png)\n",
    "\n",
    "    \n",
    "#### Hardware \n",
    "\n",
    "Neural networks ,as discussed before, continuously try to update the biases and weights.\n",
    "\n",
    "This seems to be a fairly simple task, right?\n",
    "\n",
    "Just to make you appreciate the scale of deep learning, consider [VGG16](https://www.quora.com/What-is-the-VGG-neural-network) (a convolutional neural network of 16 hidden layers which is used  in deep learning applications) It has close to `140 million parameters`(weights and biases)\n",
    "\n",
    "Obviously, it would take years to train this kind of systems if we take traditional approaches.\n",
    "\n",
    "**Graphical Processing Unit(GPU)**\n",
    "\n",
    "The advent of powerful GPUs(in the last decade itself) has played an immense role in solving this problem. GPUs are a relatively new computing model that uses massively parallel graphics processors to accelerate applications also parallel in nature. \n",
    "\n",
    "GPUs were initially created for better graphic(image) processing, but were later found to fit deep learning well. That is because most of the complex deep learning operations(both text and image) involves applying operations on large matrices, something that GPUs can handle efficiently. Along with that, Neural networks are massively parallelizable and have benefitted tremendously from modern GPU architectures.\n",
    "\n",
    "Andrew Ng(a name you are going to hear often now) was instrumental in this discovery.\n",
    "NVIDIA teamed up with Andrew Ng’s team at Stanford to use GPUs for deep learning. It is there,they figured out that 12 GPUs could deliver the deep-learning performance of 2,000 CPUs.\n",
    "\n",
    "![](../images/gpus.jpg)\n",
    "\n",
    "*CPU vs GPU. Source: [NVIDIA](https://www.nvidia.com/en-gb/ai-acceleratedanalytics/)* \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Software\n",
    "\n",
    "Another major game changer has been the new improved techniques and models that have come up to implement Deep Learning.\n",
    "\n",
    "Lot of research papers in the last decade resulted in arriving at many important algorithm insights in Neural Networks related to overcoming size limitations, improving learning rates, reducing bias and variance, learning from sparser data sets and preventing pathological behaviour.\n",
    "\n",
    "That coupled with open-source tool boxes like Tensor Flow and Keras has made building and deploying these algorithms both streamlined and simple(Also the reason why we are able to teach you this in an online course)\n",
    "\n",
    "![](../images/software.jpg)\n",
    "\n",
    "Though TensorFlow has been far and away the most commonly used software library in the field of deep learning. There are others also which are catching up quickly including PyTorch, Caffe and Theano \n",
    "\n",
    "**Note:** In our DL course, we will be coding majorly using Tensor Flow and Keras. The thing to remember though is that no framework is the optimum framework for every use case. The important thing is knowing the fundamentals(which is what the our DL courses aim for) after which shifting between the frameworks is not that difficult.\n",
    "\n",
    "\n",
    "\n",
    "## Deep Learning Pipeline\n",
    "\n",
    "Following is a typical workflow for DL problem:\n",
    "\n",
    "![](../images/NN_workflow.png)\n",
    "\n",
    "\n",
    "### Step 1 - Defining the problem \n",
    "\n",
    "While deep learning does seem capable of doing magic(if you have limited understanding of DL), it's very important to define the problem and its scope that you want to solve with the data. \n",
    "\n",
    "Expecting your Deep Learning model to come up with the problem it can solve in the data(and also have it then automatically come up with features) is wishful thinking.    \n",
    "\n",
    "\n",
    "### Step 2 - Prepare Data \n",
    "\n",
    "Though DL models figure out the features on their own, that doesn't mean that you should give the entire data to the model as it is. Removing null values, filling in missing data and normalizing/scaling features are important steps which help DL models give better predictions.\n",
    "\n",
    "For eg: If data has two features, Age(Range:[10,100]) and Salary(Range:[10000,200000]), it's obvious that the model will give more importance to Salary. If we give the model a normalized data such that both age and salary are scaled to Range:[0,1], the model will be able to work better.\n",
    "\n",
    "### Step 3 - Train the model\n",
    "\n",
    "Though DL makes data preprocessing part relatively simpler, the time saved there is more than utilized while trying to figure out the optimum architecture for the data. \n",
    "\n",
    "There are hundreds of parameters that you can choose and play with to make a Neural Network architecture including the no. of neurons, no. of layers and evaluation metric to choose.\n",
    "\n",
    "In fact, there are different optimization techinques which are specific to a use case.\n",
    "\n",
    "For e.g. All NLP(text processing) tasks are better solved with Recurrent Neural Networks(A variation of Neural Network) while Computer Vision(image/video processing) tasks can be optimised using Convolutional Neural Networks. \n",
    "\n",
    "Following are some of the different NN architectures:\n",
    "\n",
    "![](../images/nnmodels.png)\n",
    "\n",
    "* Neural networks: [Source](https://www.xenonstack.com/blog/artificial-neural-network-applications/)*\n",
    "\n",
    "\n",
    "### Step 4 - Evaluate the Model\n",
    "\n",
    "As an extension of the previous step, it is important to figure out the optimum way of evaluating the model. How to assess the model and choose the best model is a valued skill. Evaluating a model also often results in retraining it until we get the score we desire.\n",
    "\n",
    "After that it's simply just passing the data through the Neural Network to produce output. \n",
    "\n",
    "After creating a model, you can deploy it as a `web service \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Gradient Descent : Intution\n",
    "\n",
    "\n",
    "By now you have understood a bird's eye view of Deep Learning. \n",
    "\n",
    "Before we wrap up let's look at one of the techniques that was instrumental in advancement of the field of deep learning(and Machine Learning, in general) was the Gradient Descent algorithm.\n",
    "\n",
    "Gradient descent is by far the most popular optimization strategy for updating the weights and biases of the hidden layer. \n",
    "\n",
    "It is used while training of the model, can be combined with every algorithm and is fairly easy to understand and implement. Let's try to understand in brief how gradient descent works, its advantages & tradeoff and what are its different types.\n",
    "\n",
    "\n",
    "Consider the below image: <img src='../images/intuition.jpg' width=600>\n",
    "\n",
    "These three pictures represent three different situations where a ball is placed in a glass bowl at three separate positions. It is a known fact that the force of gravity will pull the ball towards the bottom of the bowl.\n",
    "\n",
    "In **situation 1**, the ball will move from position b1 to c1 and not a1. This ball will continue to travel till it reaches the bottom of the bowl. In situation 2, since the static ball is already at the bottom it will stay at b2 and it won’t move at all. In general, **the ball always tries to move from a higher potential energy state to a lower state**. Gravity is responsible for these different potential energy states of the ball.\n",
    "\n",
    "But how is this similar to gradient descent optimization? Actually, this is exactly how gradient descent optimization works. **The only major difference is that gradient descent optimization tries to minimize a loss function instead of potential energy**. \n",
    "\n",
    "Now, lets understand how the ball will roll down when it is placed in situation 1 and why does it so. In terms of the coordinate system, the potential energy reduces as the ball rolls down the Z-axis (vertical axis). The ball tries to modify its position on the X and Y-axes to determine the lowest possible potential energy or the minimum possible value on the z-axis.\n",
    "\n",
    "<img src='../images/situation.jpg' width=300>\n",
    "\n",
    "\n",
    "The gradient descent optimization can be thought of as a process similar to the rolling example in the following manner:\n",
    "- **Z-axis can be considered as the loss function**\n",
    "- **X &  Y-axes are the coefficients of the model** \n",
    "- **Loss function is equivalent to the potential energy of the ball in the bowl**\n",
    "- **Idea is to minimize loss function by adjusting X & Y-axes (i.e coefficients of the model)**\n",
    "\n",
    "\n",
    "\n",
    "Remember how you used differential calculus to find the minimum value of a function? In case you've forgotten or don't know about differential calculus do not worry, we are providing a simple example below to help you come to terms with it.\n",
    "\n",
    "Let's solve for the minimum value of the function  $f(x) : x^{4}-10x^{2}+9$  \n",
    "\n",
    "The plot for the function is shown below where the yellow and green dotted vertical lines represent the values of x for which the function has the least value.\n",
    "\n",
    "<img src='../images/fig.png'>\n",
    "\n",
    "You can find it with the help of differential calculus in the following way:\n",
    "\n",
    "1. Differentiate with respect to $x$ and set this value to $0$. Solve for $x$ in this step\n",
    "\n",
    "$$\\frac{d}{dx}f(x)= 4 x^{3}-20x = 0$$\n",
    "\n",
    "2. Solving gives values of $x$ for which the function $f(x)$ has minimum values. The value of $x$ thus found is $x = \\pm \\sqrt{5} =\\pm 2.24$ \n",
    "\n",
    "The method that we have shown just now is the **logical method**. While this method is pretty simple and straightforward, unfortunately for a lot of complicated functions, it is not possible to solve equations this way. \n",
    "\n",
    "So we need to identify some numeric methods to solve such equations which require iterative calculations. \n",
    "\n",
    "\n",
    "**ITERATIVE METHOD**\n",
    "\n",
    "Lets start with initial value of $x = 5$ for the function $f(x) : x^{4}-10x^{2}+9$ with a learning rate ($\\alpha = 0.001$). **The learning rate controls how much we are adjusting the weights with respect to the loss gradient. The lower the value, the slower we travel along the downward slope and vice-versa.** \n",
    "\n",
    "The gradient of the function for any value of x is:  $\\frac{d}{dx}(f(x)) = 4x^3 - 20x$ \n",
    "\n",
    "*FIRST ITERATION*\n",
    "\n",
    "At x = 5, the gradient is  $4.5^3 - 20.5 = 600 - 100 = 500$ \n",
    "\n",
    "Now we decrease x by an amount equal to the product of the learning rate i.e.  $\\alpha$  and the gradient at that point.\n",
    "\n",
    "So, new value of x is:  $x = 5 - 0.001*500 = 5 - 0.5 = 4.5$ \n",
    "\n",
    "**This is the new value of x at the end of the first iteration**\n",
    "\n",
    "\n",
    "*SECOND ITERATION*\n",
    "\n",
    "Following the same procedure as the first one we have,\n",
    "\n",
    "New value of x is:  $x = 4.5 - 0.001*(4.4.5^3 - 20*4.5) = 4.2255$ \n",
    "\n",
    "If we continue doing iterations in this way, it is possible to arrive the minimum value i.e. $\\sqrt{5}$.\n",
    "\n",
    "\n",
    "The loss function also decreases as the number of iterations increases and ultimately it stops after finding the optimum value of $x$ at which the loss is minimum as depicted by the image below:\n",
    "\n",
    "<img src='../images/loss.png'>\n",
    "\n",
    "\n",
    "**Analogy of the iterative method with a rolling ball**\n",
    "\n",
    "The iterative method is similar to rolling a ball downwards, and measuring its position with each calculation till it reaches the bottom. The idea is to measure the speed of the ball based on the gradient or the slope of the curve. \n",
    "\n",
    "\n",
    "Let's now briefly look at the mathematical working of Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 Gradient Descent: Mathematics approach\n",
    "\n",
    "***\n",
    "\n",
    "Let's try to break down gradient descent into simple steps.\n",
    "\n",
    "**Steps of gradient descent**\n",
    "\n",
    "Given a machine learning model(in this case a neural network) with parameters (weights i.e.  $\\theta$ ) and a cost function ( $J(\\theta)$ , we need to find a good set of weights for our model which minimizes the cost function. \n",
    "\n",
    "The step-wise procedure would be:\n",
    "\n",
    "- Start with some initial set of values for our model parameters (weights and bias) where our goal is finding the best set of model parameters by iterations. \n",
    "\n",
    "- Calculate the gradient(**G**) of the cost function at the current set of model parameters as well as the cost function to find the direction of decreasing cost function. This is the ideal direction which gives us the best model paramters.\n",
    "\n",
    "- Update the weights by an amount proportional to the calculated gradient (**G**) at the current set of model parameters i.e.  $\\theta = \\theta − \\eta G$ .\n",
    "\n",
    "- Repeat the second and third steps until the cost function stops reducing or in other words you have arrived at the global minima.\n",
    "\n",
    "The image below describes exactly what gradient descent aspires to do: <img src='../images/gd.png' width=400>\n",
    "\n",
    "\n",
    "### Learning rate\n",
    "The equation below is the weight updation formula used for gradient descent.\n",
    "\n",
    " $\\theta = \\theta − \\eta G$ \n",
    "\n",
    "One of important parameters in the equation is $\\eta$ known as learning rate.\n",
    "\n",
    "How steep the steps are that Gradient Descent takes into the direction of the local minimum are determined by the learning rate. \n",
    "\n",
    "It determines how fast or slow we will move towards the optimal weights. Therefore setting up the learning rate becomes crucial\n",
    "\n",
    "If it's set too high, it might not reach the local minimum because it will just bounce back and forth between the convex function of gradient descent. Conversely, if its set too small, time taken for gradient descent to reach the local minimum will be too much.\n",
    "\n",
    "![](../images/lr.png)\n",
    "\n",
    "\n",
    "### Types of Gradient Descent\n",
    "\n",
    "**Batch Gradient Descent**\n",
    "\n",
    "Following is its flow : <img src='../images/gdflow.png'> \n",
    "\n",
    "Although this approach of using the entire batch of training examples to update weights every time makes complete sense, with increasing number of training instances it will become more cumbersome to update model parameters. This will result in exploding training time which should be avoided using some techniques. \n",
    "\n",
    "A simple workaround is; *\"Instead of using the entire batch for training, use a single randomly selected instance for calculating gradient and update the model parameters.\"* This approach is used in our next time\n",
    "\n",
    "**Stochastic Gradient Descent (SGD)**\n",
    "\n",
    "In this method the gradient calculated is a stochastic approximation to the gradient calculated using the entire training data. Each update is much faster to calculate than in batch gradient descent, and over many updates, we will head in the same general direction. \n",
    "\n",
    "In SGD, with every  iteration, you need to shuffle the training set and pick a random training example from that.\n",
    "Since, you'll be using one training example, your path to the local minima will be very noisy like a drunk man after having one too many drinks. \n",
    "\n",
    "The flow of **SGD** can be summarized as: <img src='../images/sgcflow.png'>\n",
    "\n",
    "**Mini Batch Gradient Descent**\n",
    "\n",
    "Mini-batch Gradient Descent is the approximate combination of the SGD and Batch Gradient Descent. \n",
    "\n",
    "It simply splits the training data into `small batches` and performs the update for each of these batches. \n",
    "Therefore it results in a balance between the efficiency of batch gradient descent and the robustness of stochastic gradient descent.\n",
    "\n",
    "Common mini-batch sizes include the range between 50 and 255, though they can vary for different applications. \n",
    "With a well tuned mini-batch size, this method outperforms gradient descent or stochastic gradient descent.\n",
    "\n",
    "\n",
    "![](../images/mini_1.png)\n",
    "\n",
    "\n",
    "![](../images/mini_2.png)\n",
    "\n",
    "\n",
    "`Note:` It is the preferred  algorithm during the training of neural network\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "So there you have it, the kaleidoscopic look into deep learning.\n",
    "\n",
    "It's a subset of machine learning model where neural networks are used to solve a problem.\n",
    "It has an advantage over traditional ML models in the form of self feature generation/extraction. The recent developments in software and hardware has led to it's uncontrolled rise to the domains of healthcare, finance and general lifestyle\n",
    "\n",
    "It definitely has a lot of potential for new ideas and implementation and that's where new learners like you come in. Before we wrap it, let's just quickly eliminate the big misconception that people have about deep learning\n",
    "\n",
    "\n",
    "**Deep Learning is black art**\n",
    "\n",
    "![](../images/myth.png)\n",
    "\n",
    "\n",
    "DEEP LEARNING IS NOT BLACK ART.\n",
    "\n",
    "\n",
    "Media often portrays Deep Learning as the solution to all life’s problems. In reality, it is anything but. \n",
    "\n",
    "Think of deep learning= layered learning.\n",
    "\n",
    "For e.g. If you have a smartphone, then chances are you have softwares with speech recognition.\n",
    "\n",
    "Simple fact though is, speech recognition technology has been around for a long time, deep learning has just made it faster.\n",
    "\n",
    "It helps to think of the term of Deep learning as layered learning. Deep learning involves creating complex, hierarchical representations from simple building blocks to solve high-level problems. The network learns something simple at the initial levels , then sends the information to the next level where the information is combined to create something more complex.\n",
    "\n",
    "Admittedly though DL does have cases where we get unexplained results. \n",
    "\n",
    "There comes the another problem. Deep learning is enabling machine learning in a way that is both exciting and dizzying. Fact is it's a technology for which we don't completely understand the algorithms driving it. \n",
    "\n",
    "That is why it is so critical for data scientists implementing Deep Learning to understand the basics of deep learning. By demanding proof and reasoning in each part of the development process, one can build a robust framework amongst the unlimited number of model permutations.\n",
    "\n",
    "\n",
    "With that out, let's delve into the detailed concepts of the Deep Learning.\n",
    "\n",
    "Happy Learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "\n",
    "Q-1: AI is a subset of Machine Learning\n",
    "\n",
    "A. True\n",
    "\n",
    "B. False [Correct Answer]\n",
    "\n",
    "\n",
    "Explanation: It's the opposite. `Artificial intelligence` is the broad domain involving any technique that enables computers to mimic human behaviour and think intelligently whereas `Machine learning` is but a subset of artificial intelligence where without being explicitly programmed, machines are able to learn the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-2: Which of the following is 'not' a major reason for the sudden emergence of Deep Learning?\n",
    "\n",
    "\n",
    "A. Advent of new hardware and technologies\n",
    "\n",
    "B. Rise of Big Data\n",
    "\n",
    "C. Neither of the options [Correct Answer]\n",
    "\n",
    "Explanation: Both the advent of hardware/software along with the explosion of Big Data has led to the rise of research and applications in Deep Learning. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-3: In which of the following use cases traditional ML models are not preferred?\n",
    "\n",
    "A. Credit Card Fraud Detection\n",
    "\n",
    "B. Identification of licence plate numbers from traffic images[Correct Answer]\n",
    "\n",
    "Explanation: Identification of licence plate numbers requires non scalable feature selection and engineering. Hence Deep learning models, and not traditional ML models should be preferred. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-4: Gradient descent is a classification algorithm\n",
    "\n",
    "A. False [Correct Answer]\n",
    "\n",
    "B. True\n",
    "\n",
    "Explanation: Gradient descent is an optimization algorithm for the machine to learn weights and biases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-5: Which hardware architecture is optimised for implementing Deep Learning?\n",
    "\n",
    "A. CPU\n",
    "\n",
    "B. GPU [Correct Answer]\n",
    "\n",
    "Explanation:GPU .This is because most of the complex deep learning operations involves applying operations on large matrices and that is something GPUs can handle efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-6: Which of the following is not an application of Deep Learning?\n",
    "\n",
    "A. Restoration of colour in B/W images\n",
    "\n",
    "B. Document summarization\n",
    "\n",
    "C. Employee Appraisal[Correct Answer]\n",
    "\n",
    "Explanation: Employee Appraisal would traditionally be a rule based system application. Employee hours, his contribution to team, etc would be the features and appraisal can be set using simple if-else statements.\n",
    "\n",
    "The remaining two are applications of Deep Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-7: Deep Learning model only requires raw data to be fed into it.\n",
    "\n",
    "A. False [Correct Answer]\n",
    "\n",
    "B. True\n",
    "\n",
    "Explanation: Deep learning models rarely end up being correct when fed raw data. Cleaning of data before the model setup and optimizing the subsequent model(neural network) architecture are important for getting good results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-8: The “deep” part in deep learning refers to the name 'Michael Deep' who was a pioneer in that field.\n",
    "\n",
    "A. True \n",
    "\n",
    "B. False [Correct Answer]\n",
    "\n",
    "Explanation: The “deep” part in deep learning refers to creating deep neural networks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
